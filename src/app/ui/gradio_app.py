# src/app/ui/gradio_app.py
from __future__ import annotations

import uuid
import gradio as gr

from src.app.graph.app import build_app
import openai

# í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œ 1ë²ˆë§Œ ìƒì„±
APP = build_app(enable_interrupt=False)

TEST_1 = "123*987 ê³„ì‚°í•´ì¤˜"
TEST_2 = "PDFì—ì„œ ë°©ê¸ˆ ë„£ì€ ë¬¸ì„œ ë‚´ìš© ìš”ì•½í•´ì¤˜"
TEST_3 = "ì‚¬ìš©ìëŠ” Gradio UIë¥¼ ì›í•¨ì„ profileë¡œ importance 4 tags uië¡œ ì €ì¥í•´ì¤˜"


def _append(chat_history: list[dict], role: str, content: str) -> list[dict]:
    chat_history = chat_history or []
    chat_history.append({"role": role, "content": content})
    return chat_history


def _invoke(user_text: str, chat_history: list[dict], thread_id: str):
    user_text = (user_text or "").strip()
    if not user_text:
        return chat_history, ""

    cfg = {"configurable": {"thread_id": thread_id}}

    st = {
        "messages": [{"role": "user", "content": user_text}],
        "tool_calls": None,
        "steps": 0,
    }

    try:
        out = APP.invoke(st, config=cfg)
        msg = out["messages"][-1]
        assistant_text = msg.content if hasattr(msg, "content") else str(msg)

        chat_history = _append(chat_history, "user", user_text)
        chat_history = _append(chat_history, "assistant", assistant_text)
        return chat_history, ""

    except openai.BadRequestError as e:
        # ğŸ”¥ í•µì‹¬: ê¹¨ì§„ thread ë²„ë¦¬ê³  ìƒˆ thread ìƒì„±
        chat_history = _append(chat_history, "assistant",
            "âš ï¸ ë‚´ë¶€ ìƒíƒœ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
        )
        return chat_history, ""



def _run_test(prompt: str, chat_history: list[dict], thread_id: str):
    return _invoke(prompt, chat_history, thread_id)


def build_gradio():
    with gr.Blocks() as demo:
        gr.Markdown("## SOFT Agent (LangGraph + Tools/RAG/Memory)")

        thread = gr.State(str(uuid.uuid4()))
        chat = gr.Chatbot(height=420)

        with gr.Row():
            inp = gr.Textbox(label="ë©”ì‹œì§€", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”â€¦", scale=8)
            btn = gr.Button("Send", scale=2)

        with gr.Row():
            t1 = gr.Button("TEST 1: ê³„ì‚°ê¸°")
            t2 = gr.Button("TEST 2: RAG ìš”ì•½")
            t3 = gr.Button("TEST 3: ë©”ëª¨ë¦¬ ì €ì¥")

        with gr.Row():
            reset = gr.Button("New Thread")

        # ì „ì†¡
        btn.click(_invoke, inputs=[inp, chat, thread], outputs=[chat, inp])
        inp.submit(_invoke, inputs=[inp, chat, thread], outputs=[chat, inp])

        # í…ŒìŠ¤íŠ¸ ë²„íŠ¼ë“¤
        t1.click(lambda h, tid: _run_test(TEST_1, h, tid), inputs=[chat, thread], outputs=[chat, inp])
        t2.click(lambda h, tid: _run_test(TEST_2, h, tid), inputs=[chat, thread], outputs=[chat, inp])
        t3.click(lambda h, tid: _run_test(TEST_3, h, tid), inputs=[chat, thread], outputs=[chat, inp])

        # ìƒˆ ëŒ€í™”(ìƒˆ thread_id + chat ì´ˆê¸°í™”)
        def new_thread():
            return [], str(uuid.uuid4())

        reset.click(new_thread, outputs=[chat, thread])

        gr.Markdown(
            "- TEST 2ê°€ ë™ì‘í•˜ë ¤ë©´ RAG ì¸ë±ì‹±ì´ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n"
            "- thread_idë¥¼ ìœ ì§€í•´ì„œ ê°™ì€ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤."
        )

    return demo
